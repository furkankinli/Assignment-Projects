{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Already up-to-date.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import git\n",
    "g = git.cmd.Git('/root/Projects/Assignment-Projects')\n",
    "g.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Sparker.SparkLogProcesser.SparkLogFileHandler import setSparkContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext() \n",
    "setSparkContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoExistsOnUCSC/Parsed/2016-09-28_parsed has been read by 2017-05-18 01:38:02.260549\n"
     ]
    }
   ],
   "source": [
    "from Sparker.Logic.LogicTests import *\n",
    "day2Logs = readParsedLogsFromHDFS(entireDayParsedLogsFolder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from MainSrc.PythonVersionHandler import *\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Sparker.Logic.LogicTests import *\n",
    "from Sparker.Logic.Trainer import *\n",
    "#trainPairWiseData(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printSeparater(c = 3):\n",
    "    for n in range(c):\n",
    "        print_('#' * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def evaluateModelOnData(model, data, dataName = 'Data', modelName = 'Model'):\n",
    "    labelsAndPreds = data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    truePredictionCount = labelsAndPreds.filter(lambda vp: vp[0] == vp[1]).count()\n",
    "    instanceCount = data.count()\n",
    "    accuracy = 100 * truePredictionCount / float(instanceCount)\n",
    "    print_('\\n'+modelName, 'has been evaluated on', dataName, 'by', nowStr())\n",
    "    print_('The result accuracy is %' + '%.3f\\n' % (accuracy))\n",
    "    return labelsAndPreds\n",
    "\n",
    "def trainPairWiseData(data, dataName = 'Data', modelName = 'Model', evaluate = True):\n",
    "    print_('Training...')\n",
    "    model = SVMWithSGD.train(data, iterations=100)\n",
    "    print_('\\n', modelName, 'has been trained on', dataName, 'by', nowStr())##\n",
    "    print_('The learned weights:\\n' + str(model.weights).replace(',', ', ') + '\\n')\n",
    "    if evaluate:\n",
    "        evaluateModelOnData(model, data, dataName, modelName)\n",
    "    return model\n",
    "\n",
    "def runTrainingExperiment(trainData, testData, modelName = 'Model', save = True, outputFolder = Day1_iPhone_6_DataFolder):\n",
    "    trainData = normalizeTrainData(trainData)\n",
    "    testData = normalizeTrainData(testData)\n",
    "    model = trainPairWiseData(trainData, 'trainData', modelName)\n",
    "    if save:\n",
    "        modelPath = joinPath(outputFolder, modelName)\n",
    "        try:\n",
    "            model.save(sc_(), modelPath)\n",
    "        except Py4JJavaError:\n",
    "            pass\n",
    "        print_(modelPath, 'has been saved successfully by', nowStr())\n",
    "    return evaluateModelOnData(model, testData, 'testData', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateModelOnDataSK(model, data, dataName = 'Data', modelName = 'Model'):\n",
    "    labelsAndPreds = data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    truePredictionCount = labelsAndPreds.filter(lambda vp: vp[0] == vp[1]).count()\n",
    "    instanceCount = data.count()\n",
    "    accuracy = 100 * truePredictionCount / float(instanceCount)\n",
    "    print_('\\n'+modelName, 'has been evaluated on', dataName, 'by', nowStr())\n",
    "    print_('The result accuracy is %' + '%.3f\\n' % (accuracy))\n",
    "    return labelsAndPreds\n",
    "\n",
    "def trainPairWiseDataSK(data, dataName = 'Data', modelName = 'Model', evaluate = True):\n",
    "    model = svm.SVC()#kernel =  'poly', degree = 3) #\n",
    "    size = 5000\n",
    "    X =  data.map(lambda p: p.features).collect()[:size]\n",
    "    Y =  data.map(lambda p: p.label).collect()[:size]\n",
    "    print_('Training...')\n",
    "    model.fit(X, Y)\n",
    "    print_('\\n', modelName, 'has been trained on', dataName, 'by', nowStr())##\n",
    "   # print_('The learned weights:\\n' + str(model.coef_).replace(',', ', ') + '\\n')\n",
    "    if evaluate:\n",
    "        evaluateModelOnDataSK(model, data, dataName, modelName)\n",
    "    return model\n",
    "\n",
    "def runTrainingExperimentSK(trainData, testData, modelName = 'Model', save = True, outputFolder = Day1_iPhone_6_DataFolder):\n",
    "    preprocessing = scaleTrainData# normalizeTrainData#\n",
    "    trainData = preprocessing(trainData)\n",
    "    testData = preprocessing(testData)\n",
    "    model = trainPairWiseDataSK(trainData, 'trainData', modelName)\n",
    "    if save:\n",
    "        modelPath = joinPath(outputFolder, modelName)\n",
    "        try:\n",
    "            model.save(sc_(), modelPath)\n",
    "        except Py4JJavaError:\n",
    "            pass\n",
    "        print_(modelPath, 'has been saved successfully by', nowStr())\n",
    "    return evaluateModelOnDataSK(model, testData, 'testData', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from DeepLearningToRank.DeepDataHandler import *\n",
    "#from DeepLearningToRank.DeepTrainer import *\n",
    "\n",
    "def featureFilter(trainData):\n",
    "    return trainData.map(lambda x: LabeledPoint(x.label, list(x.features[1:4]) + list(x.features[5:6]) + list(x.features[7:-2])))\n",
    "\n",
    "def runExperiment(trainData, modelName = 'Model'):\n",
    "    printSeparater(1)\n",
    "    testData, trainData = trainData.randomSplit(weights=[0.3, 0.7])\n",
    "    #testData, trainData = trainData[:int(30*len(trainData)/100)], trainData[int(30*len(trainData)/100):]\n",
    "    runTrainingExperimentSK(trainData, testData, modelName = modelName, save = False)\n",
    "    print_('The experiment for', modelName, 'has been completed by', nowStr())\n",
    "    printSeparater(1)\n",
    "    \n",
    "def trainPairWiseDataTestKeyword2(keyword):\n",
    "    printSeparater(2)\n",
    "    keyword = keyword.replace(' ', '_')\n",
    "    inputName = 'all_day'\n",
    "    outputFolder = joinPath(joinPath(textTrainDataFolder, 'HDFS'), 'Day1_' + keyword + '_Data')\n",
    "    trainDataFile = joinPath(outputFolder, inputName + '_' + keyword + '_TrainData')\n",
    "    trainData = readTrainDataFromHDFS(trainDataFile)\n",
    "    runExperiment(trainData, modelName = 'ExtendedModel')\n",
    "    trainData = featureFilter(trainData)\n",
    "    runExperiment(trainData, modelName = 'FilteredModel')\n",
    "    printSeparater(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "/soe/cicekm/Projects/offlineData/HDFS/Day1_iphone_6_Data/all_day_iphone_6_TrainData has been read successfully by 2017-05-18 01:53:42.025153\n",
      "########################################################################################\n",
      "584638 instances have been scaled by 2017-05-18 01:53:49.116502\n",
      "251054 instances have been scaled by 2017-05-18 01:53:55.340841\n",
      "Training...\n",
      "\n",
      " ExtendedModel has been trained on trainData by 2017-05-18 01:54:14.611165\n",
      "\n",
      "ExtendedModel has been evaluated on trainData by 2017-05-18 01:55:00.093311\n",
      "The result accuracy is %68.427\n",
      "\n",
      "\n",
      "ExtendedModel has been evaluated on testData by 2017-05-18 01:55:26.582242\n",
      "The result accuracy is %68.374\n",
      "\n",
      "The experiment for ExtendedModel has been completed by 2017-05-18 01:55:26.598797\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "584857 instances have been scaled by 2017-05-18 01:55:35.558863\n",
      "250835 instances have been scaled by 2017-05-18 01:55:44.501987\n",
      "Training...\n",
      "\n",
      " FilteredModel has been trained on trainData by 2017-05-18 01:56:08.532187\n",
      "\n",
      "FilteredModel has been evaluated on trainData by 2017-05-18 01:56:56.824142\n",
      "The result accuracy is %65.393\n",
      "\n",
      "\n",
      "FilteredModel has been evaluated on testData by 2017-05-18 01:57:27.809984\n",
      "The result accuracy is %65.254\n",
      "\n",
      "The experiment for FilteredModel has been completed by 2017-05-18 01:57:27.829953\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "trainPairWiseDataTestKeyword2('iphone 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savePairWisetrainData(keyword):\n",
    "    printSeparater(2)\n",
    "    keyword = keyword.replace(' ', '_')\n",
    "    inputName = 'all_day'\n",
    "    outputFolder = joinPath(HDFSDataFolder, 'Day1_' + keyword + '_Data')\n",
    "    dataTypes = ['_TrainData', '_labeledPairs', '_journey_products']\n",
    "    for typ in dataTypes:\n",
    "        fileName = inputName + '_' + keyword + typ\n",
    "        trainDataFile = joinPath(outputFolder, fileName)\n",
    "        trainData = sc_().textFile(trainDataFile)\n",
    "        f = joinPath('/root/Projects/TrainData6', fileName)\n",
    "        trainData = trainData.collect()\n",
    "        fp = open(f, \"wb\")   #Pickling\n",
    "        pickle.dump(trainData, fp)\n",
    "        print_(f, 'has been saved successfully by', nowStr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainPairWiseDataTest():\n",
    "    keywords = ['iphone 6', 'jant', 'nike air max', 'tv unitesi', 'kot ceket', 'camasir makinesi', 'bosch']\n",
    "    for keyword in keywords:\n",
    "        #trainPairWiseDataTestKeyword2(keyword)readTrainDataFromHDFS\n",
    "        savePairWisetrainData(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    printSeparater()\n",
    "    print_('%s:' % nowStr(), 'Running on osldevptst02:Jupyter...')\n",
    "\n",
    "    trainPairWiseDataTest()\n",
    "\n",
    "    print_('%s:' % nowStr(), 'DONE')\n",
    "    printSeparater()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "2017-05-09 15:09:16.404133: Running on osldevptst02:Jupyter...\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "/root/Projects/TrainData6/all_day_tv_unitesi_TrainData has been saved successfully by 2017-05-09 15:09:35.835378\n",
      "/root/Projects/TrainData6/all_day_tv_unitesi_labeledPairs has been saved successfully by 2017-05-09 15:09:56.224687\n",
      "/root/Projects/TrainData6/all_day_tv_unitesi_journey_products has been saved successfully by 2017-05-09 15:09:58.585784\n",
      "2017-05-09 15:09:58.589724: DONE\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
