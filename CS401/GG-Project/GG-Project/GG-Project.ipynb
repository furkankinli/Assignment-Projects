{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Already up-to-date.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import git\n",
    "g = git.cmd.Git('/root/Projects/Assignment-Projects')\n",
    "g.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Sparker.SparkLogProcesser.SparkLogFileHandler import setSparkContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext() \n",
    "setSparkContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoExistsOnUCSC/Parsed/2016-09-28_parsed has been read by 2017-05-19 04:46:25.370486\n"
     ]
    }
   ],
   "source": [
    "from Sparker.Logic.LogicTests import *\n",
    "day2Logs = readParsedLogsFromHDFS(entireDayParsedLogsFolder2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from MainSrc.PythonVersionHandler import *\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Sparker.Logic.LogicTests import *\n",
    "from Sparker.Logic.Trainer import *\n",
    "#trainPairWiseData(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printSeparater(c = 3):\n",
    "    for n in range(c):\n",
    "        print_('#' * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def evaluateModelOnData(model, data, dataName = 'Data', modelName = 'Model'):\n",
    "    labelsAndPreds = data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    truePredictionCount = labelsAndPreds.filter(lambda vp: vp[0] == vp[1]).count()\n",
    "    instanceCount = data.count()\n",
    "    accuracy = 100 * truePredictionCount / float(instanceCount)\n",
    "    print_('\\n'+modelName, 'has been evaluated on', dataName, 'by', nowStr())\n",
    "    print_('The result accuracy is %' + '%.3f\\n' % (accuracy))\n",
    "    return labelsAndPreds\n",
    "\n",
    "def trainPairWiseData(data, dataName = 'Data', modelName = 'Model', evaluate = True):\n",
    "    print_('Training...')\n",
    "    model = SVMWithSGD.train(data, iterations=100)\n",
    "    print_('\\n', modelName, 'has been trained on', dataName, 'by', nowStr())##\n",
    "    print_('The learned weights:\\n' + str(model.weights).replace(',', ', ') + '\\n')\n",
    "    if evaluate:\n",
    "        evaluateModelOnData(model, data, dataName, modelName)\n",
    "    return model\n",
    "\n",
    "def runTrainingExperiment(trainData, testData, modelName = 'Model', save = True, outputFolder = Day1_iPhone_6_DataFolder):\n",
    "    model = trainPairWiseData(trainData, 'trainData', modelName)\n",
    "    if save:\n",
    "        modelPath = joinPath(outputFolder, modelName)\n",
    "        try:\n",
    "            model.save(sc_(), modelPath)\n",
    "        except Py4JJavaError:\n",
    "            pass\n",
    "        print_(modelPath, 'has been saved successfully by', nowStr())\n",
    "    return evaluateModelOnData(model, testData, 'testData', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateModelOnDataSK(model, data, dataName = 'Data', modelName = 'Model'):\n",
    "    labelsAndPreds = data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "    truePredictionCount = labelsAndPreds.filter(lambda vp: vp[0] == vp[1]).count()\n",
    "    instanceCount = data.count()\n",
    "    accuracy = 100 * truePredictionCount / float(instanceCount)\n",
    "    print_('\\n'+modelName, 'has been evaluated on', dataName, 'by', nowStr())\n",
    "    print_('The result accuracy is %' + '%.3f\\n' % (accuracy))\n",
    "    return labelsAndPreds\n",
    "\n",
    "def trainPairWiseDataSK(data, dataName = 'Data', modelName = 'Model', evaluate = True):\n",
    "    model = svm.SVC()#kernel =  'poly', degree = 3) #[:size][:size]\n",
    "    size = 5000\n",
    "    X =  data.map(lambda p: p.features).collect()\n",
    "    Y =  data.map(lambda p: p.label).collect()\n",
    "    print_('Training...')\n",
    "    model.fit(X, Y)\n",
    "    print_('\\n', modelName, 'has been trained on', dataName, 'by', nowStr())##\n",
    "   # print_('The learned weights:\\n' + str(model.coef_).replace(',', ', ') + '\\n')\n",
    "    if evaluate:\n",
    "        evaluateModelOnDataSK(model, data, dataName, modelName)\n",
    "    return model\n",
    "\n",
    "def runTrainingExperimentSK(trainData, testData, modelName = 'Model', save = True, outputFolder = Day1_iPhone_6_DataFolder):\n",
    "    model = trainPairWiseDataSK(trainData, 'trainData', modelName)\n",
    "    if save:\n",
    "        modelPath = joinPath(outputFolder, modelName)\n",
    "        try:\n",
    "            model.save(sc_(), modelPath)\n",
    "        except Py4JJavaError:\n",
    "            pass\n",
    "        print_(modelPath, 'has been saved successfully by', nowStr())\n",
    "    return evaluateModelOnDataSK(model, testData, 'testData', modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepLearningToRank.DeepDataHandler import readTrainDataFromPickle\n",
    "#from DeepLearningToRank.DeepTrainer import *\n",
    "\n",
    "def featureFilter(trainData):\n",
    "    return trainData.map(lambda x: LabeledPoint(x.label, list(x.features[1:4]) + list(x.features[5:6]) + list(x.features[7:-2])))\n",
    "\n",
    "def runExperiment(trainData, modelName = 'Model'):\n",
    "    printSeparater(1)\n",
    "    testData, trainData = trainData.randomSplit(weights=[0.3, 0.7])\n",
    "    #testData, trainData = trainData[:int(30*len(trainData)/100)], trainData[int(30*len(trainData)/100):]SK\n",
    "    runTrainingExperiment(trainData, testData, modelName = modelName, save = False)\n",
    "    print_('The experiment for', modelName, 'has finished by', nowStr())\n",
    "    \n",
    "def trainPairWiseDataTestKeyword2(keyword, location = 'HDF.S'):\n",
    "    printSeparater(2)\n",
    "    keyword = keyword.replace(' ', '_')\n",
    "    inputName = 'all_day'\n",
    "    if location == 'HDFS':\n",
    "        outputFolder = joinPath(joinPath(textTrainDataFolder, 'HDFS'), 'Day1_' + keyword + '_Data')\n",
    "        trainDataFile = joinPath(outputFolder, inputName + '_' + keyword + '_TrainData')\n",
    "        trainData = readTrainDataFromHDFS(trainDataFile)\n",
    "    else:\n",
    "        trainDataFile = joinPath(textTrainDataFolder, inputName + '_' + keyword + '_TrainData.txt')\n",
    "        trainData = readTrainDataFromPickle(trainDataFile)\n",
    "        trainData = sc_().parallelize(trainData)\n",
    "        trainData = trainData.map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "    print_(trainData.first())\n",
    "    preprocessing = scaleTrainData# normalizeTrainData#\n",
    "    trainData = preprocessing(trainData)\n",
    "    runExperiment(trainData, modelName = 'ExtendedModel')\n",
    "    trainData = featureFilter(trainData)\n",
    "    runExperiment(trainData, modelName = 'FilteredModel')\n",
    "    printSeparater(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "/soe/cicekm/Projects/offlineData/all_day_iphone_6_TrainData.txt has been read successfully by 2017-05-19 05:25:41.983985\n",
      "(1.0,[0.0,15.0,100.0,-4001.0,1.0,1.0,0.0,1.0,0.0,1.0,75.3,-780.0])\n",
      "835692 instances have been scaled by 2017-05-19 05:25:48.258672\n",
      "########################################################################################\n",
      "Training...\n",
      "\n",
      " ExtendedModel has been trained on trainData by 2017-05-19 05:26:41.854098\n",
      "The learned weights:\n",
      "[-0.0135669704447, 0.693874282493, 0.0365743330955, 0.0167163902482, 0.0352732652536, 0.180662009167, -0.656961146254, 0.165403902962, 0.293123576531, 0.511020110259, 1.1648170067, -0.212257484789]\n",
      "\n",
      "\n",
      "ExtendedModel has been evaluated on trainData by 2017-05-19 05:26:50.599279\n",
      "The result accuracy is %89.993\n",
      "\n",
      "\n",
      "ExtendedModel has been evaluated on testData by 2017-05-19 05:26:59.295167\n",
      "The result accuracy is %89.944\n",
      "\n",
      "The experiment for ExtendedModel has finished by 2017-05-19 05:26:59.316134\n",
      "########################################################################################\n",
      "Training...\n",
      "\n",
      " FilteredModel has been trained on trainData by 2017-05-19 05:27:53.425269\n",
      "The learned weights:\n",
      "[0.6007863159, -0.102518113421, -0.461719233483, 0.123906607885, 0.0703034786075, 0.355523120434, 0.575825875491]\n",
      "\n",
      "\n",
      "FilteredModel has been evaluated on trainData by 2017-05-19 05:28:06.876685\n",
      "The result accuracy is %69.810\n",
      "\n",
      "\n",
      "FilteredModel has been evaluated on testData by 2017-05-19 05:28:19.297245\n",
      "The result accuracy is %69.957\n",
      "\n",
      "The experiment for FilteredModel has finished by 2017-05-19 05:28:19.319755\n",
      "########################################################################################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "trainPairWiseDataTestKeyword2('iphone 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savePairWisetrainData(keyword):\n",
    "    printSeparater(2)\n",
    "    keyword = keyword.replace(' ', '_')\n",
    "    inputName = 'all_day'\n",
    "    outputFolder = joinPath(HDFSDataFolder, 'Day1_' + keyword + '_Data')\n",
    "    dataTypes = ['_TrainData', '_labeledPairs', '_journey_products']\n",
    "    for typ in dataTypes:\n",
    "        fileName = inputName + '_' + keyword + typ\n",
    "        trainDataFile = joinPath(outputFolder, fileName)\n",
    "        trainData = sc_().textFile(trainDataFile)\n",
    "        f = joinPath('/root/Projects/TrainData6', fileName)\n",
    "        trainData = trainData.collect()\n",
    "        fp = open(f, \"wb\")   #Pickling\n",
    "        pickle.dump(trainData, fp)\n",
    "        print_(f, 'has been saved successfully by', nowStr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainPairWiseDataTest():\n",
    "    keywords = ['iphone 6', 'jant', 'nike air max', 'tv unitesi', 'kot ceket', 'camasir makinesi', 'bosch']\n",
    "    for keyword in keywords:\n",
    "        #trainPairWiseDataTestKeyword2(keyword)readTrainDataFromHDFS\n",
    "        savePairWisetrainData(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    printSeparater()\n",
    "    print_('%s:' % nowStr(), 'Running on osldevptst02:Jupyter...')\n",
    "\n",
    "    trainPairWiseDataTest()\n",
    "\n",
    "    print_('%s:' % nowStr(), 'DONE')\n",
    "    printSeparater()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "2017-05-09 15:09:16.404133: Running on osldevptst02:Jupyter...\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "/root/Projects/TrainData6/all_day_tv_unitesi_TrainData has been saved successfully by 2017-05-09 15:09:35.835378\n",
      "/root/Projects/TrainData6/all_day_tv_unitesi_labeledPairs has been saved successfully by 2017-05-09 15:09:56.224687\n",
      "/root/Projects/TrainData6/all_day_tv_unitesi_journey_products has been saved successfully by 2017-05-09 15:09:58.585784\n",
      "2017-05-09 15:09:58.589724: DONE\n",
      "########################################################################################\n",
      "########################################################################################\n",
      "########################################################################################\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
