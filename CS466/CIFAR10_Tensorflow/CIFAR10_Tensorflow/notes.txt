######################################################################################## 
######################################################################################## 
######################################################################################## 
######################################################################################## 
2017-04-29 12:18:47.896763: Running... 
You must pass exactly 3 arguments to this program, 
Example usage: 
python muratcan_cicek_training.py network_1 28x28_dataset /path/to/dataset/folder 
Extracting /root/Projects/Assignment-Projects/CS466/MNIST_Tensorflow/MNIST_Tensorflow/t10k-images.idx3-ubyte 
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
The First Network on 28x28_dataset running...
 
Epoch 10, training accuracy on the last batch = 1.00
Epoch 20, training accuracy on the last batch = 1.00
Epoch 30, training accuracy on the last batch = 1.00
Epoch 40, training accuracy on the last batch = 1.00
Epoch 50, training accuracy on the last batch = 1.00
Epoch 60, training accuracy on the last batch = 1.00
Epoch 70, training accuracy on the last batch = 1.00
Epoch 80, training accuracy on the last batch = 1.00
Epoch 90, training accuracy on the last batch = 1.00
The test accuracy = 0.978 
  
2017-04-29 12:41:26.262986: DONE 
######################################################################################## 
######################################################################################## 
######################################################################################## 
######################################################################################## 
2017-04-29 17:30:59.803608: step 120860, loss = 0.71 (879.3 examples/sec; 0.146 sec/batch)
2017-04-29 17:31:01.376721: step 120870, loss = 0.65 (813.7 examples/sec; 0.157 sec/batch)
2017-04-29 17:31:03.023384: step 120880, loss = 0.50 (777.3 examples/sec; 0.165 sec/batch)
2017-04-29 17:31:04.485968: step 120890, loss = 0.72 (875.2 examples/sec; 0.146 sec/batch)
2017-04-29 17:31:06.287336: step 120900, loss = 0.79 (710.6 examples/sec; 0.180 sec/batch)
2017-04-29 17:31:07.485620: step 120910, loss = 0.78 (1068.2 examples/sec; 0.120 sec/batch)
2017-04-29 17:31:08.933643: step 120920, loss = 0.65 (884.0 examples/sec; 0.145 sec/batch)
2017-04-29 17:31:10.480600: step 120930, loss = 0.78 (827.4 examples/sec; 0.155 sec/batch)
2017-04-29 17:31:11.971093: step 120940, loss = 0.73 (858.8 examples/sec; 0.149 sec/batch)
2017-04-29 17:31:13.511061: step 120950, loss = 0.71 (831.2 examples/sec; 0.154 sec/batch)
2017-04-29 17:31:15.035265: step 120960, loss = 0.62 (839.8 examples/sec; 0.152 sec/batch)
2017-04-29 17:31:16.503221: step 120970, loss = 0.69 (872.0 examples/sec; 0.147 sec/batch)
2017-04-29 17:31:18.070259: step 120980, loss = 0.83 (816.8 examples/sec; 0.157 sec/batch)
2017-04-29 17:31:19.534280: step 120990, loss = 0.71 (874.3 examples/sec; 0.146 sec/batch)
2017-04-29 17:31:21.459352: step 121000, loss = 0.82 (664.9 examples/sec; 0.193 sec/batch)
2017-04-29 17:31:22.732181: step 121010, loss = 0.67 (1005.6 examples/sec; 0.127 sec/batch)
2017-04-29 17:31:24.225354: step 121020, loss = 0.64 (857.2 examples/sec; 0.149 sec/batch)
2017-04-29 17:31:25.669089: step 121030, loss = 0.62 (886.6 examples/sec; 0.144 sec/batch)
2017-04-29 17:31:27.112279: step 121040, loss = 0.81 (886.9 examples/sec; 0.144 sec/batch)
2017-04-29 17:31:28.564460: step 121050, loss = 0.71 (881.4 examples/sec; 0.145 sec/batch)
2017-04-29 17:31:30.145437: step 121060, loss = 0.73 (809.6 examples/sec; 0.158 sec/batch)
2017-04-29 17:31:31.640331: step 121070, loss = 0.74 (856.2 examples/sec; 0.149 sec/batch)
2017-04-29 17:31:33.178771: step 121080, loss = 0.67 (832.0 examples/sec; 0.154 sec/batch)
2017-04-29 17:31:34.688450: step 121090, loss = 0.58 (847.9 examples/sec; 0.151 sec/batch)
2017-04-29 17:31:36.489586: step 121100, loss = 0.64 (710.9 examples/sec; 0.180 sec/batch)
2017-04-29 17:31:37.689626: step 121110, loss = 0.74 (1066.2 examples/sec; 0.120 sec/batch)
2017-04-29 17:31:39.160898: step 121120, loss = 0.93 (870.0 examples/sec; 0.147 sec/batch)
2017-04-29 17:31:40.671861: step 121130, loss = 0.58 (847.1 examples/sec; 0.151 sec/batch)
2017-04-29 17:31:42.169647: step 121140, loss = 0.63 (854.6 examples/sec; 0.150 sec/batch)
2017-04-29 17:31:43.650945: step 121150, loss = 0.67 (864.1 examples/sec; 0.148 sec/batch)
2017-04-29 17:31:45.143303: step 121160, loss = 0.77 (857.7 examples/sec; 0.149 sec/batch)
2017-04-29 17:31:46.721063: step 121170, loss = 0.68 (811.3 examples/sec; 0.158 sec/batch)
2017-04-29 17:31:48.200686: step 121180, loss = 0.64 (865.1 examples/sec; 0.148 sec/batch)
2017-04-29 17:31:49.709509: step 121190, loss = 0.84 (848.3 examples/sec; 0.151 sec/batch)
2017-04-29 17:31:51.499882: step 121200, loss = 0.75 (714.9 examples/sec; 0.179 sec/batch)
2017-04-29 17:31:52.726187: step 121210, loss = 0.75 (1043.8 examples/sec; 0.123 sec/batch)
2017-04-29 17:31:54.182001: step 121220, loss = 0.68 (879.8 examples/sec; 0.145 sec/batch)
2017-04-29 17:31:55.664829: step 121230, loss = 0.65 (862.6 examples/sec; 0.148 sec/batch)
2017-04-29 17:31:57.142769: step 121240, loss = 0.66 (866.1 examples/sec; 0.148 sec/batch)
2017-04-29 17:31:58.575982: step 121250, loss = 0.76 (893.1 examples/sec; 0.143 sec/batch)
2017-04-29 17:32:00.048429: step 121260, loss = 0.49 (869.3 examples/sec; 0.147 sec/batch)
2017-04-29 17:32:01.679373: step 121270, loss = 0.64 (784.8 examples/sec; 0.163 sec/batch)
2017-04-29 17:32:03.177946: step 121280, loss = 0.76 (854.1 examples/sec; 0.150 sec/batch)
2017-04-29 17:32:04.681857: step 121290, loss = 0.70 (851.1 examples/sec; 0.150 sec/batch)
2017-04-29 17:32:06.419537: step 121300, loss = 0.74 (736.6 examples/sec; 0.174 sec/batch)
2017-04-29 17:32:07.651710: step 121310, loss = 0.63 (1038.8 examples/sec; 0.123 sec/batch) GPU OF MY MSI
######################################################################################## 
######################################################################################## 
######################################################################################## 
######################################################################################## 
2017-04-29 17:39:51.882944: step 2050, loss = 1.54 (458.0 examples/sec; 0.279 sec/batch)
2017-04-29 17:39:54.685732: step 2060, loss = 1.48 (456.7 examples/sec; 0.280 sec/batch)
2017-04-29 17:39:57.467454: step 2070, loss = 1.52 (460.1 examples/sec; 0.278 sec/batch)
2017-04-29 17:40:00.278815: step 2080, loss = 1.73 (455.3 examples/sec; 0.281 sec/batch)
2017-04-29 17:40:03.191250: step 2090, loss = 1.58 (439.5 examples/sec; 0.291 sec/batch)
2017-04-29 17:40:06.084839: step 2100, loss = 1.72 (442.4 examples/sec; 0.289 sec/batch)
2017-04-29 17:40:08.921586: step 2110, loss = 1.59 (451.2 examples/sec; 0.284 sec/batch)
2017-04-29 17:40:13.380331: step 2120, loss = 1.58 (287.1 examples/sec; 0.446 sec/batch)
2017-04-29 17:40:16.156990: step 2130, loss = 1.51 (461.0 examples/sec; 0.278 sec/batch)
2017-04-29 17:40:18.941438: step 2140, loss = 1.72 (459.7 examples/sec; 0.278 sec/batch)
2017-04-29 17:40:21.739555: step 2150, loss = 1.59 (457.5 examples/sec; 0.280 sec/batch) SERVER OF GITTIGIDIYOR (CPU) with 64 GB ram etc. 
######################################################################################## 
######################################################################################## 
######################################################################################## 
######################################################################################## 
2017-04-29 18:03:08.723038: step 21890, loss = 0.79 (185.0 examples/sec; 0.692 sec/batch)
2017-04-29 18:03:15.689574: step 21900, loss = 0.76 (183.7 examples/sec; 0.697 sec/batch)
2017-04-29 18:03:22.547065: step 21910, loss = 0.74 (186.7 examples/sec; 0.686 sec/batch)
2017-04-29 18:03:29.567765: step 21920, loss = 0.80 (182.3 examples/sec; 0.702 sec/batch)
2017-04-29 18:03:36.498096: step 21930, loss = 0.79 (184.7 examples/sec; 0.693 sec/batch)
2017-04-29 18:03:43.369779: step 21940, loss = 0.84 (186.3 examples/sec; 0.687 sec/batch)
2017-04-29 18:03:50.105158: step 21950, loss = 0.85 (190.0 examples/sec; 0.674 sec/batch)
2017-04-29 18:03:57.008290: step 21960, loss = 1.01 (185.4 examples/sec; 0.690 sec/batch)
2017-04-29 18:04:03.852757: step 21970, loss = 0.89 (187.0 examples/sec; 0.684 sec/batch)
2017-04-29 18:04:10.478639: step 21980, loss = 0.85 (193.2 examples/sec; 0.663 sec/batch)
2017-04-29 18:04:17.314429: step 21990, loss = 0.83 (187.2 examples/sec; 0.684 sec/batch)
2017-04-29 18:04:25.042034: step 22000, loss = 0.85 (165.6 examples/sec; 0.773 sec/batch)
2017-04-29 18:04:32.684203: step 22010, loss = 0.78 (167.5 examples/sec; 0.764 sec/batch) MAC PRO (CPU)
########################################################################################
########################################################################################
########################################################################################
2017-05-01 15:21:54.054698: step 10, loss = 4.61 (1799.5 examples/sec; 0.071 sec/batch)
2017-05-01 15:21:55.487813: step 20, loss = 4.55 (1783.4 examples/sec; 0.072 sec/batch)
2017-05-01 15:21:56.911359: step 30, loss = 4.31 (1834.5 examples/sec; 0.070 sec/batch)
########################################################################################
########################################################################################
########################################################################################
2017-05-01 15:21:27.927647: Running on server...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: Tesla K20c
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:03:00.0
Total memory: 4.63GiB
Free memory: 4.57GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x567c4f0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties:
name: Tesla K20c
major: 3 minor: 5 memoryClockRate (GHz) 0.7055
pciBusID 0000:43:00.0
Total memory: 4.63GiB
Free memory: 4.57GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20c, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20c, pci bus id: 0000:43:00.0)
2017-05-01 15:21:51.235804: step 0, loss = 4.67 (14.6 examples/sec; 8.771 sec/batch)
2017-05-01 15:21:54.054698: step 10, loss = 4.61 (1799.5 examples/sec; 0.071 sec/batch)
2017-05-01 15:21:55.487813: step 20, loss = 4.55 (1783.4 examples/sec; 0.072 sec/batch)
2017-05-01 15:21:56.911359: step 30, loss = 4.31 (1834.5 examples/sec; 0.070 sec/batch)
2017-05-01 15:21:58.316040: step 40, loss = 4.31 (1808.1 examples/sec; 0.071 sec/batch)
2017-05-01 15:21:59.747394: step 50, loss = 4.31 (1824.6 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:01.170882: step 60, loss = 4.26 (1809.5 examples/sec; 0.071 sec/batch)
2017-05-01 15:22:02.597701: step 70, loss = 4.14 (1612.8 examples/sec; 0.079 sec/batch)
2017-05-01 15:22:04.023675: step 80, loss = 4.23 (1822.4 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:05.432368: step 90, loss = 4.20 (1831.8 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:06.855312: step 100, loss = 4.13 (1838.5 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:08.453513: step 110, loss = 4.06 (1802.4 examples/sec; 0.071 sec/batch)
2017-05-01 15:22:09.879151: step 120, loss = 4.10 (1802.6 examples/sec; 0.071 sec/batch)
2017-05-01 15:22:11.320827: step 130, loss = 4.04 (1832.9 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:12.761198: step 140, loss = 3.97 (1634.1 examples/sec; 0.078 sec/batch)
2017-05-01 15:22:14.164299: step 150, loss = 3.79 (1841.8 examples/sec; 0.069 sec/batch)
2017-05-01 15:22:15.592426: step 160, loss = 3.84 (1817.0 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:17.031728: step 170, loss = 3.81 (1815.9 examples/sec; 0.070 sec/batch)
2017-05-01 15:22:18.442208: step 180, loss = 3.88 (1756.6 examples/sec; 0.073 sec/batch)
2017-05-01 15:22:19.883740: step 190, loss = 3.81 (1754.6 examples/sec; 0.073 sec/batch)
2017-05-01 15:22:21.310602: step 200, loss = 4.01 (1789.5 examples/sec; 0.072 sec/batch)
2017-05-01 15:22:22.914951: step 210, loss = 3.92 (1709.0 examples/sec; 0.075 sec/batch)
2017-05-01 15:22:24.352541: step 220, loss = 3.73 (1737.3 examples/sec; 0.074 sec/batch)
2017-05-01 15:22:25.797563: step 230, loss = 3.83 (1791.3 examples/sec; 0.071 sec/batch)
2017-05-01 15:22:27.216711: step 240, loss = 3.57 (1777.9 examples/sec; 0.072 sec/batch)
2017-05-01 15:22:28.634092: step 250, loss = 3.56 (1814.1 examples/sec; 0.071 sec/batch)
2017-05-01 15:22:30.058819: step 260, loss = 3.49 (1795.0 examples/sec; 0.071 sec/batch)
2017-05-01 15:22:31.480049: step 270, loss = 3.66 (1748.2 examples/sec; 0.073 sec/batch)
2017-05-01 15:22:32.896824: step 280, loss = 3.69 (1843.0 examples/sec; 0.069 sec/batch)
2017-05-01 15:22:34.325433: step 290, loss = 3.49 (1885.7 examples/sec; 0.068 sec/batch)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K20c, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K20c, pci bus id: 0000:43:00.0)
2017-05-01 15:22:39.083543: precision @ 1 = 0.496
2017-05-01 15:22:39.351331: DONE
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
########################################################################################
2017-05-02 19:42:16.698996: Running on MSI...
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "BestSplits" device_type: "CPU"') for unknown op: BestSplits
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "CountExtremelyRandomStats" device_type: "CPU"') for unknown op: CountExtremelyRandomStats
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "FinishedNodes" device_type: "CPU"') for unknown op: FinishedNodes
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "GrowTree" device_type: "CPU"') for unknown op: GrowTree
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "ReinterpretStringToFloat" device_type: "CPU"') for unknown op: ReinterpretStringToFloat
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "SampleInputs" device_type: "CPU"') for unknown op: SampleInputs
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "ScatterAddNdim" device_type: "CPU"') for unknown op: ScatterAddNdim
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "TopNInsert" device_type: "CPU"') for unknown op: TopNInsert
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "TopNRemove" device_type: "CPU"') for unknown op: TopNRemove
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "TreePredictions" device_type: "CPU"') for unknown op: TreePredictions
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "UpdateFertileSlots" device_type: "CPU"') for unknown op: UpdateFertileSlots
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 880M
major: 3 minor: 0 memoryClockRate (GHz) 0.993
pciBusID 0000:01:00.0
Total memory: 8.00GiB
Free memory: 6.73GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 880M, pci bus id: 0000:01:00.0)
2017-05-02 19:42:26.526405: step 0, loss = 6.38 (1818.8 examples/sec; 0.070 sec/batch)
2017-05-02 19:44:14.946251: step 100, loss = 5.90 (118.1 examples/sec; 1.084 sec/batch)
2017-05-02 19:46:18.165279: step 200, loss = 5.10 (103.9 examples/sec; 1.232 sec/batch)
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 880M, pci bus id: 0000:01:00.0)
2017-05-02 19:48:03.199919: precision @ 1 = 0.545
2017-05-02 19:48:03.914295: DONE
########################################################################################
########################################################################################
########################################################################################